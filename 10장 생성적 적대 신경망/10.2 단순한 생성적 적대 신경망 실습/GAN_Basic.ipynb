{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN_Basic.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"collapsed":true,"id":"LEsLLsywQxDa","colab_type":"text"},"source":["# GAN Basic\n","\n","- Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks(https://arxiv.org/pdf/1511.06434.pdf)\n","- Multi-GPU 사용법\n","- Sequential에 OrderedDict를 전달하는 예시\n","\n","![대체 텍스트](http://www.codingwoman.com/wp-content/uploads/2018/09/gan-2-700x529.jpg)"]},{"cell_type":"code","metadata":{"id":"RXCdVxRERQTs","colab_type":"code","outputId":"259f7c1b-3fab-4dd8-807c-618066367596","executionInfo":{"status":"ok","timestamp":1559570593742,"user_tz":-540,"elapsed":5009,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["!pip install torch torchvision"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7aHU2RT5Tin5","colab_type":"code","outputId":"ce4fe0f3-8c80-44f2-f3ff-b78a3c95dd18","executionInfo":{"status":"ok","timestamp":1559570600811,"user_tz":-540,"elapsed":12043,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":290}},"source":["!pip install pillow==4.1.1\n","%reload_ext autoreload\n","%autoreload"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting pillow==4.1.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/e5/88b3d60924a3f8476fa74ec086f5fbaba56dd6cee0d82845f883b6b6dd18/Pillow-4.1.1-cp36-cp36m-manylinux1_x86_64.whl (5.7MB)\n","\u001b[K     |████████████████████████████████| 5.7MB 15.7MB/s \n","\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow==4.1.1) (0.46)\n","\u001b[31mERROR: scikit-image 0.15.0 has requirement pillow>=4.3.0, but you'll have pillow 4.1.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: pillow\n","  Found existing installation: Pillow 4.3.0\n","    Uninstalling Pillow-4.3.0:\n","      Successfully uninstalled Pillow-4.3.0\n","Successfully installed pillow-4.1.1\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"D6RunB_GQxDd","colab_type":"text"},"source":["## 1. Import required libraries"]},{"cell_type":"code","metadata":{"id":"sPxeYi1UQxDd","colab_type":"code","colab":{}},"source":["# 단순한 GAN 모델 생성 및 OrderedDict 사용법\n","\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.utils as utils\n","import torch.nn.init as init\n","import torchvision.utils as v_utils\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from collections import OrderedDict"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7bQFaHXQdjco","colab_type":"code","outputId":"c032401f-ea41-412b-ab73-6e994de99891","executionInfo":{"status":"ok","timestamp":1559570600819,"user_tz":-540,"elapsed":12030,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# 참고\n","# 전치 컨볼루션 연산으로 이미지 크기를 2배로 늘리는 방법 2가지\n","# 둘중에 kernel_size=4,stride=2,padding=1 세팅이 체커보드 아티팩트가 덜합니다.\n","\n","test = torch.ones(1,1,16,16)\n","conv1 = nn.ConvTranspose2d(1,1,kernel_size=4,stride=2,padding=1)\n","out = conv1(test)\n","print(out.size())\n","\n","conv1 = nn.ConvTranspose2d(1,1,kernel_size=3,stride=2,padding=1,output_padding=1)\n","out = conv1(test)\n","print(out.size())"],"execution_count":4,"outputs":[{"output_type":"stream","text":["torch.Size([1, 1, 32, 32])\n","torch.Size([1, 1, 32, 32])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FAXNbJZKQxDh","colab_type":"text"},"source":["## 2. Hyperparameter setting"]},{"cell_type":"code","metadata":{"id":"euV-AUuqQxDi","colab_type":"code","colab":{}},"source":["# Set Hyperparameters\n","# change num_gpu to the number of gpus you want to use\n","\n","epoch = 50\n","batch_size = 512\n","learning_rate = 0.0002\n","num_gpus = 1\n","z_size = 50\n","middle_size = 200"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fm7I7r9gQxDl","colab_type":"text"},"source":["## 3. Data Setting"]},{"cell_type":"code","metadata":{"id":"x7ffMZoKQxDm","colab_type":"code","colab":{}},"source":["# Download Data\n","\n","mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n","\n","# Set Data Loader(input pipeline)\n","\n","train_loader = torch.utils.data.DataLoader(dataset=mnist_train,batch_size=batch_size,shuffle=True,drop_last=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h4Qg3pn8QxDp","colab_type":"text"},"source":["## 4. Generator"]},{"cell_type":"code","metadata":{"id":"TxKtzC8ZQxDr","colab_type":"code","colab":{}},"source":["# Generator receives random noise z and create 1x28x28 image\n","# OrderedDict를 사용해 해당 연산의 이름을 지정할 수 있습니다.\n","\n","class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator,self).__init__()\n","        self.layer1 = nn.Sequential(OrderedDict([\n","                        ('fc1',nn.Linear(z_size,middle_size)),\n","                        ('bn1',nn.BatchNorm1d(middle_size)),\n","                        ('act1',nn.ReLU()),\n","        ]))\n","        self.layer2 = nn.Sequential(OrderedDict([\n","                        ('fc2', nn.Linear(middle_size,784)),\n","                        #('bn2', nn.BatchNorm1d(784)),\n","                        ('tanh', nn.Tanh()),\n","        ]))\n","    def forward(self,z):\n","        out = self.layer1(z)\n","        out = self.layer2(out)\n","        out = out.view(batch_size,1,28,28)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SrWbwGDdQxDt","colab_type":"text"},"source":["## 5. Discriminator"]},{"cell_type":"code","metadata":{"id":"CreP2LF1QxDu","colab_type":"code","colab":{}},"source":["# Discriminator receives 1x28x28 image and returns a float number 0~1\n","# we can name each layer using OrderedDict\n","\n","class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator,self).__init__()\n","        self.layer1 = nn.Sequential(OrderedDict([\n","                        ('fc1',nn.Linear(784,middle_size)),\n","                        #('bn1',nn.BatchNorm1d(middle_size)),\n","                        ('act1',nn.LeakyReLU()),  \n","            \n","        ]))\n","        self.layer2 = nn.Sequential(OrderedDict([\n","                        ('fc2', nn.Linear(middle_size,1)),\n","                        ('bn2', nn.BatchNorm1d(1)),\n","                        ('act2', nn.Sigmoid()),\n","        ]))\n","                                    \n","    def forward(self,x):\n","        out = x.view(batch_size, -1)\n","        out = self.layer1(out)\n","        out = self.layer2(out)\n","        return out"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YJsHifpXQxDx","colab_type":"text"},"source":["## 6. Put instances on Multi-gpu"]},{"cell_type":"code","metadata":{"id":"9SmfWh7RQxDy","colab_type":"code","outputId":"7af67ee9-ded2-4a17-feb8-4c3128afbae4","executionInfo":{"status":"ok","timestamp":1559570605575,"user_tz":-540,"elapsed":16772,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Put class objects on Multiple GPUs using \n","# torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)\n","# device_ids: default all devices / output_device: default device 0 \n","# along with .cuda()\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","print(device)\n","\n","generator = nn.DataParallel(Generator()).to(device)\n","discriminator = nn.DataParallel(Discriminator()).to(device)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FQU6hgtNQxD1","colab_type":"text"},"source":["## 7. Check layers"]},{"cell_type":"code","metadata":{"id":"fYyp82HLQxD2","colab_type":"code","outputId":"0c2a3420-40d6-4b83-fe91-00ae69f9701b","executionInfo":{"status":"ok","timestamp":1559570605578,"user_tz":-540,"elapsed":16763,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["# Get parameter list by using class.state_dict().keys()\n","\n","gen_params = generator.state_dict().keys()\n","dis_params = discriminator.state_dict().keys()\n","\n","for i in gen_params:\n","    print(i)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["module.layer1.fc1.weight\n","module.layer1.fc1.bias\n","module.layer1.bn1.weight\n","module.layer1.bn1.bias\n","module.layer1.bn1.running_mean\n","module.layer1.bn1.running_var\n","module.layer1.bn1.num_batches_tracked\n","module.layer2.fc2.weight\n","module.layer2.fc2.bias\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8BfH5Y1KQxD8","colab_type":"text"},"source":["## 8. Set Loss function & Optimizer"]},{"cell_type":"code","metadata":{"id":"ou1pGOjpQxD8","colab_type":"code","colab":{}},"source":["# loss function, optimizers, and labels for training\n","\n","loss_func = nn.MSELoss()\n","gen_optim = torch.optim.Adam(generator.parameters(), lr=learning_rate,betas=(0.5,0.999))\n","dis_optim = torch.optim.Adam(discriminator.parameters(), lr=learning_rate,betas=(0.5,0.999))\n","\n","ones_label = torch.ones(batch_size,1).to(device)\n","zeros_label = torch.zeros(batch_size,1).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7tgsDe6xQxD-","colab_type":"text"},"source":["## 9. Restore Model"]},{"cell_type":"code","metadata":{"id":"1xHe1BvWQxD_","colab_type":"code","outputId":"2003dc6b-2ba2-4940-eb92-38e39390d28f","executionInfo":{"status":"ok","timestamp":1559570605620,"user_tz":-540,"elapsed":16797,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# model restore if any\n","\n","try:\n","    generator, discriminator = torch.load('./model/vanilla_gan.pkl')\n","    print(\"\\n--------model restored--------\\n\")\n","except:\n","    print(\"\\n--------model not restored--------\\n\")\n","    pass\n","  \n","try:\n","  os.mkdir(\"./model\")\n","except:\n","  pass\n","\n","try:\n","  os.mkdir(\"./result\")\n","except:\n","  pass"],"execution_count":12,"outputs":[{"output_type":"stream","text":["\n","--------model not restored--------\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_6KCS2YQQxEC","colab_type":"text"},"source":["## 10. Train Model"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"0aZOP-GXQxED","colab_type":"code","outputId":"4277350e-5c06-4c81-88c2-eba3853b06a0","executionInfo":{"status":"ok","timestamp":1559570876939,"user_tz":-540,"elapsed":288104,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":3505}},"source":["# train\n","\n","for i in range(epoch):\n","    for j,(image,label) in enumerate(train_loader):\n","        image = image.to(device)\n","        \n","        # 구분자 학습\n","        dis_optim.zero_grad()\n","      \n","        # Fake Data \n","        # 랜덤한 z를 샘플링해줍니다.\n","        z = init.normal_(torch.Tensor(batch_size,z_size),mean=0,std=0.1).to(device)\n","        gen_fake = generator.forward(z)\n","        dis_fake = discriminator.forward(gen_fake)\n","        \n","        # Real Data\n","        dis_real = discriminator.forward(image)\n","        \n","        # 두 손실을 더해 최종손실에 대해 기울기 게산을 합니다.\n","        dis_loss = torch.sum(loss_func(dis_fake,zeros_label)) + torch.sum(loss_func(dis_real,ones_label))\n","        dis_loss.backward(retain_graph=True)\n","        dis_optim.step()\n","        \n","        # 생성자 학습\n","        gen_optim.zero_grad()\n","        \n","        # Fake Data\n","        z = init.normal_(torch.Tensor(batch_size,z_size),mean=0,std=0.1).to(device)\n","        gen_fake = generator.forward(z)\n","        dis_fake = discriminator.forward(gen_fake)\n","        \n","        gen_loss = torch.sum(loss_func(dis_fake,ones_label)) # fake classified as real\n","        gen_loss.backward()\n","        gen_optim.step()\n","    \n","        # model save\n","        if j % 100 == 0:\n","            print(gen_loss,dis_loss)\n","            torch.save([generator,discriminator],'./model/vanilla_gan.pkl')            \n","            v_utils.save_image(gen_fake.cpu().data[0:25],\"./result/gen_{}_{}.png\".format(i,j), nrow=5)\n","            print(\"{}th epoch gen_loss: {} dis_loss: {}\".format(i,gen_loss.data,dis_loss.data))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["tensor(0.2669, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.5319, device='cuda:0', grad_fn=<AddBackward0>)\n","0th epoch gen_loss: 0.26688629388809204 dis_loss: 0.5318572521209717\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Generator. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Discriminator. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"},{"output_type":"stream","text":["tensor(0.2673, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.5021, device='cuda:0', grad_fn=<AddBackward0>)\n","0th epoch gen_loss: 0.267328679561615 dis_loss: 0.5021049976348877\n","tensor(0.2643, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.5013, device='cuda:0', grad_fn=<AddBackward0>)\n","1th epoch gen_loss: 0.2642729878425598 dis_loss: 0.5012626647949219\n","tensor(0.2614, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.5062, device='cuda:0', grad_fn=<AddBackward0>)\n","1th epoch gen_loss: 0.26135867834091187 dis_loss: 0.5062186121940613\n","tensor(0.2550, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.5073, device='cuda:0', grad_fn=<AddBackward0>)\n","2th epoch gen_loss: 0.25496113300323486 dis_loss: 0.5072519779205322\n","tensor(0.2615, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.5123, device='cuda:0', grad_fn=<AddBackward0>)\n","2th epoch gen_loss: 0.2614646553993225 dis_loss: 0.5123181939125061\n","tensor(0.2659, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.5143, device='cuda:0', grad_fn=<AddBackward0>)\n","3th epoch gen_loss: 0.2658843994140625 dis_loss: 0.5143462419509888\n","tensor(0.2677, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4937, device='cuda:0', grad_fn=<AddBackward0>)\n","3th epoch gen_loss: 0.2677236795425415 dis_loss: 0.4936519265174866\n","tensor(0.2655, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4959, device='cuda:0', grad_fn=<AddBackward0>)\n","4th epoch gen_loss: 0.2654716968536377 dis_loss: 0.4959478974342346\n","tensor(0.2604, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4913, device='cuda:0', grad_fn=<AddBackward0>)\n","4th epoch gen_loss: 0.2604326605796814 dis_loss: 0.49125418066978455\n","tensor(0.2682, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4929, device='cuda:0', grad_fn=<AddBackward0>)\n","5th epoch gen_loss: 0.26822584867477417 dis_loss: 0.4928636848926544\n","tensor(0.2609, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.5022, device='cuda:0', grad_fn=<AddBackward0>)\n","5th epoch gen_loss: 0.26091092824935913 dis_loss: 0.5022352933883667\n","tensor(0.2608, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.5009, device='cuda:0', grad_fn=<AddBackward0>)\n","6th epoch gen_loss: 0.2607639729976654 dis_loss: 0.5009434223175049\n","tensor(0.2620, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4992, device='cuda:0', grad_fn=<AddBackward0>)\n","6th epoch gen_loss: 0.2619919776916504 dis_loss: 0.49920058250427246\n","tensor(0.2627, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4979, device='cuda:0', grad_fn=<AddBackward0>)\n","7th epoch gen_loss: 0.2626658082008362 dis_loss: 0.4978848397731781\n","tensor(0.2596, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4956, device='cuda:0', grad_fn=<AddBackward0>)\n","7th epoch gen_loss: 0.25955531001091003 dis_loss: 0.49555569887161255\n","tensor(0.2604, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4948, device='cuda:0', grad_fn=<AddBackward0>)\n","8th epoch gen_loss: 0.26035091280937195 dis_loss: 0.4948384761810303\n","tensor(0.2595, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4940, device='cuda:0', grad_fn=<AddBackward0>)\n","8th epoch gen_loss: 0.2595457136631012 dis_loss: 0.4939711093902588\n","tensor(0.2597, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4936, device='cuda:0', grad_fn=<AddBackward0>)\n","9th epoch gen_loss: 0.25970128178596497 dis_loss: 0.49358779191970825\n","tensor(0.2607, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4934, device='cuda:0', grad_fn=<AddBackward0>)\n","9th epoch gen_loss: 0.26072874665260315 dis_loss: 0.4934326410293579\n","tensor(0.2607, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4931, device='cuda:0', grad_fn=<AddBackward0>)\n","10th epoch gen_loss: 0.26065999269485474 dis_loss: 0.4931458830833435\n","tensor(0.2611, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4921, device='cuda:0', grad_fn=<AddBackward0>)\n","10th epoch gen_loss: 0.2611161470413208 dis_loss: 0.49211326241493225\n","tensor(0.2612, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4921, device='cuda:0', grad_fn=<AddBackward0>)\n","11th epoch gen_loss: 0.26115837693214417 dis_loss: 0.4920697510242462\n","tensor(0.2617, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4929, device='cuda:0', grad_fn=<AddBackward0>)\n","11th epoch gen_loss: 0.2617323696613312 dis_loss: 0.49293753504753113\n","tensor(0.2617, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4918, device='cuda:0', grad_fn=<AddBackward0>)\n","12th epoch gen_loss: 0.26169106364250183 dis_loss: 0.4917815923690796\n","tensor(0.2624, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4909, device='cuda:0', grad_fn=<AddBackward0>)\n","12th epoch gen_loss: 0.2624257206916809 dis_loss: 0.49092239141464233\n","tensor(0.2626, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4942, device='cuda:0', grad_fn=<AddBackward0>)\n","13th epoch gen_loss: 0.26262128353118896 dis_loss: 0.49421465396881104\n","tensor(0.2629, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4907, device='cuda:0', grad_fn=<AddBackward0>)\n","13th epoch gen_loss: 0.26289063692092896 dis_loss: 0.49073800444602966\n","tensor(0.2632, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4908, device='cuda:0', grad_fn=<AddBackward0>)\n","14th epoch gen_loss: 0.2631687521934509 dis_loss: 0.49081844091415405\n","tensor(0.2637, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4896, device='cuda:0', grad_fn=<AddBackward0>)\n","14th epoch gen_loss: 0.26365926861763 dis_loss: 0.48955750465393066\n","tensor(0.2639, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4897, device='cuda:0', grad_fn=<AddBackward0>)\n","15th epoch gen_loss: 0.26389145851135254 dis_loss: 0.48971402645111084\n","tensor(0.2647, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4887, device='cuda:0', grad_fn=<AddBackward0>)\n","15th epoch gen_loss: 0.2646523118019104 dis_loss: 0.48868125677108765\n","tensor(0.2645, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4882, device='cuda:0', grad_fn=<AddBackward0>)\n","16th epoch gen_loss: 0.26454469561576843 dis_loss: 0.4881998896598816\n","tensor(0.2652, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4879, device='cuda:0', grad_fn=<AddBackward0>)\n","16th epoch gen_loss: 0.26521390676498413 dis_loss: 0.48793482780456543\n","tensor(0.2653, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4876, device='cuda:0', grad_fn=<AddBackward0>)\n","17th epoch gen_loss: 0.26529598236083984 dis_loss: 0.4876001179218292\n","tensor(0.2660, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4872, device='cuda:0', grad_fn=<AddBackward0>)\n","17th epoch gen_loss: 0.2660332918167114 dis_loss: 0.48724645376205444\n","tensor(0.2663, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4886, device='cuda:0', grad_fn=<AddBackward0>)\n","18th epoch gen_loss: 0.26634928584098816 dis_loss: 0.48864954710006714\n","tensor(0.2664, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4868, device='cuda:0', grad_fn=<AddBackward0>)\n","18th epoch gen_loss: 0.2664227783679962 dis_loss: 0.48675858974456787\n","tensor(0.2670, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4863, device='cuda:0', grad_fn=<AddBackward0>)\n","19th epoch gen_loss: 0.2670401334762573 dis_loss: 0.48632121086120605\n","tensor(0.2686, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4862, device='cuda:0', grad_fn=<AddBackward0>)\n","19th epoch gen_loss: 0.26861274242401123 dis_loss: 0.4862130284309387\n","tensor(0.2689, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4858, device='cuda:0', grad_fn=<AddBackward0>)\n","20th epoch gen_loss: 0.26894691586494446 dis_loss: 0.4858161509037018\n","tensor(0.2707, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4853, device='cuda:0', grad_fn=<AddBackward0>)\n","20th epoch gen_loss: 0.27071425318717957 dis_loss: 0.4853368401527405\n","tensor(0.2712, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4847, device='cuda:0', grad_fn=<AddBackward0>)\n","21th epoch gen_loss: 0.2711961567401886 dis_loss: 0.4846982955932617\n","tensor(0.2725, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4836, device='cuda:0', grad_fn=<AddBackward0>)\n","21th epoch gen_loss: 0.2724975347518921 dis_loss: 0.4836091101169586\n","tensor(0.2726, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4836, device='cuda:0', grad_fn=<AddBackward0>)\n","22th epoch gen_loss: 0.2725919783115387 dis_loss: 0.48357394337654114\n","tensor(0.2736, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4833, device='cuda:0', grad_fn=<AddBackward0>)\n","22th epoch gen_loss: 0.27363869547843933 dis_loss: 0.4833016097545624\n","tensor(0.2738, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4829, device='cuda:0', grad_fn=<AddBackward0>)\n","23th epoch gen_loss: 0.27382877469062805 dis_loss: 0.4828634262084961\n","tensor(0.2750, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4811, device='cuda:0', grad_fn=<AddBackward0>)\n","23th epoch gen_loss: 0.27504637837409973 dis_loss: 0.48111602663993835\n","tensor(0.2748, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4845, device='cuda:0', grad_fn=<AddBackward0>)\n","24th epoch gen_loss: 0.2747601270675659 dis_loss: 0.4844761788845062\n","tensor(0.2760, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4805, device='cuda:0', grad_fn=<AddBackward0>)\n","24th epoch gen_loss: 0.27595090866088867 dis_loss: 0.48053205013275146\n","tensor(0.2762, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4806, device='cuda:0', grad_fn=<AddBackward0>)\n","25th epoch gen_loss: 0.2762370705604553 dis_loss: 0.48061397671699524\n","tensor(0.2769, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4811, device='cuda:0', grad_fn=<AddBackward0>)\n","25th epoch gen_loss: 0.27686750888824463 dis_loss: 0.48111552000045776\n","tensor(0.2770, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4793, device='cuda:0', grad_fn=<AddBackward0>)\n","26th epoch gen_loss: 0.27703893184661865 dis_loss: 0.47925013303756714\n","tensor(0.2780, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4784, device='cuda:0', grad_fn=<AddBackward0>)\n","26th epoch gen_loss: 0.2780243158340454 dis_loss: 0.4784480333328247\n","tensor(0.2781, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4785, device='cuda:0', grad_fn=<AddBackward0>)\n","27th epoch gen_loss: 0.27810588479042053 dis_loss: 0.47853365540504456\n","tensor(0.2786, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4773, device='cuda:0', grad_fn=<AddBackward0>)\n","27th epoch gen_loss: 0.2786130905151367 dis_loss: 0.47732114791870117\n","tensor(0.2789, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4767, device='cuda:0', grad_fn=<AddBackward0>)\n","28th epoch gen_loss: 0.2788686156272888 dis_loss: 0.47665470838546753\n","tensor(0.2797, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4763, device='cuda:0', grad_fn=<AddBackward0>)\n","28th epoch gen_loss: 0.2797497510910034 dis_loss: 0.4762556254863739\n","tensor(0.2800, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4773, device='cuda:0', grad_fn=<AddBackward0>)\n","29th epoch gen_loss: 0.2799670994281769 dis_loss: 0.4773462116718292\n","tensor(0.2810, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4745, device='cuda:0', grad_fn=<AddBackward0>)\n","29th epoch gen_loss: 0.2809831202030182 dis_loss: 0.47449395060539246\n","tensor(0.2815, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4742, device='cuda:0', grad_fn=<AddBackward0>)\n","30th epoch gen_loss: 0.28148069977760315 dis_loss: 0.4741680920124054\n","tensor(0.2824, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4739, device='cuda:0', grad_fn=<AddBackward0>)\n","30th epoch gen_loss: 0.2823547422885895 dis_loss: 0.47391054034233093\n","tensor(0.2823, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4728, device='cuda:0', grad_fn=<AddBackward0>)\n","31th epoch gen_loss: 0.28227469325065613 dis_loss: 0.4727590084075928\n","tensor(0.2833, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4736, device='cuda:0', grad_fn=<AddBackward0>)\n","31th epoch gen_loss: 0.28333720564842224 dis_loss: 0.4735894799232483\n","tensor(0.2833, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4715, device='cuda:0', grad_fn=<AddBackward0>)\n","32th epoch gen_loss: 0.2833377718925476 dis_loss: 0.47150909900665283\n","tensor(0.2860, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4704, device='cuda:0', grad_fn=<AddBackward0>)\n","32th epoch gen_loss: 0.28600960969924927 dis_loss: 0.47044795751571655\n","tensor(0.2864, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4709, device='cuda:0', grad_fn=<AddBackward0>)\n","33th epoch gen_loss: 0.28640252351760864 dis_loss: 0.47090816497802734\n","tensor(0.2882, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4702, device='cuda:0', grad_fn=<AddBackward0>)\n","33th epoch gen_loss: 0.2882136404514313 dis_loss: 0.470150887966156\n","tensor(0.2885, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4703, device='cuda:0', grad_fn=<AddBackward0>)\n","34th epoch gen_loss: 0.2885478734970093 dis_loss: 0.4702666401863098\n","tensor(0.2900, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4694, device='cuda:0', grad_fn=<AddBackward0>)\n","34th epoch gen_loss: 0.29004839062690735 dis_loss: 0.4694017171859741\n","tensor(0.2905, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4701, device='cuda:0', grad_fn=<AddBackward0>)\n","35th epoch gen_loss: 0.29054608941078186 dis_loss: 0.47008225321769714\n","tensor(0.2918, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4680, device='cuda:0', grad_fn=<AddBackward0>)\n","35th epoch gen_loss: 0.29179561138153076 dis_loss: 0.4679693579673767\n","tensor(0.2919, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4675, device='cuda:0', grad_fn=<AddBackward0>)\n","36th epoch gen_loss: 0.29188427329063416 dis_loss: 0.4674886465072632\n","tensor(0.2932, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4666, device='cuda:0', grad_fn=<AddBackward0>)\n","36th epoch gen_loss: 0.2932184338569641 dis_loss: 0.46659180521965027\n","tensor(0.2932, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4715, device='cuda:0', grad_fn=<AddBackward0>)\n","37th epoch gen_loss: 0.29323387145996094 dis_loss: 0.47151777148246765\n","tensor(0.2944, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4656, device='cuda:0', grad_fn=<AddBackward0>)\n","37th epoch gen_loss: 0.29442793130874634 dis_loss: 0.4655805826187134\n","tensor(0.2946, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4645, device='cuda:0', grad_fn=<AddBackward0>)\n","38th epoch gen_loss: 0.29458990693092346 dis_loss: 0.4644705355167389\n","tensor(0.2956, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4629, device='cuda:0', grad_fn=<AddBackward0>)\n","38th epoch gen_loss: 0.2955520749092102 dis_loss: 0.4628611207008362\n","tensor(0.2959, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4632, device='cuda:0', grad_fn=<AddBackward0>)\n","39th epoch gen_loss: 0.2959061861038208 dis_loss: 0.4631515443325043\n","tensor(0.2974, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4628, device='cuda:0', grad_fn=<AddBackward0>)\n","39th epoch gen_loss: 0.29744189977645874 dis_loss: 0.46284985542297363\n","tensor(0.2973, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4631, device='cuda:0', grad_fn=<AddBackward0>)\n","40th epoch gen_loss: 0.2972815930843353 dis_loss: 0.4630752503871918\n","tensor(0.3003, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4601, device='cuda:0', grad_fn=<AddBackward0>)\n","40th epoch gen_loss: 0.30026930570602417 dis_loss: 0.4601000249385834\n","tensor(0.3007, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4602, device='cuda:0', grad_fn=<AddBackward0>)\n","41th epoch gen_loss: 0.300703763961792 dis_loss: 0.46021780371665955\n","tensor(0.3031, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4597, device='cuda:0', grad_fn=<AddBackward0>)\n","41th epoch gen_loss: 0.3031408190727234 dis_loss: 0.4597213864326477\n","tensor(0.3031, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4604, device='cuda:0', grad_fn=<AddBackward0>)\n","42th epoch gen_loss: 0.303135484457016 dis_loss: 0.46037912368774414\n","tensor(0.3042, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4582, device='cuda:0', grad_fn=<AddBackward0>)\n","42th epoch gen_loss: 0.3042016923427582 dis_loss: 0.4582497477531433\n","tensor(0.3048, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4575, device='cuda:0', grad_fn=<AddBackward0>)\n","43th epoch gen_loss: 0.3047522306442261 dis_loss: 0.45753198862075806\n","tensor(0.3062, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4564, device='cuda:0', grad_fn=<AddBackward0>)\n","43th epoch gen_loss: 0.30623358488082886 dis_loss: 0.45639437437057495\n","tensor(0.3066, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4567, device='cuda:0', grad_fn=<AddBackward0>)\n","44th epoch gen_loss: 0.30664896965026855 dis_loss: 0.4567081928253174\n","tensor(0.3076, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4554, device='cuda:0', grad_fn=<AddBackward0>)\n","44th epoch gen_loss: 0.3076115548610687 dis_loss: 0.4553830027580261\n","tensor(0.3080, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4550, device='cuda:0', grad_fn=<AddBackward0>)\n","45th epoch gen_loss: 0.3079652190208435 dis_loss: 0.45504918694496155\n","tensor(0.3096, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4540, device='cuda:0', grad_fn=<AddBackward0>)\n","45th epoch gen_loss: 0.30961668491363525 dis_loss: 0.45398324728012085\n","tensor(0.3158, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4566, device='cuda:0', grad_fn=<AddBackward0>)\n","46th epoch gen_loss: 0.31576159596443176 dis_loss: 0.4566183090209961\n","tensor(0.3089, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4536, device='cuda:0', grad_fn=<AddBackward0>)\n","46th epoch gen_loss: 0.30891990661621094 dis_loss: 0.45361894369125366\n","tensor(0.3090, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4530, device='cuda:0', grad_fn=<AddBackward0>)\n","47th epoch gen_loss: 0.30896833539009094 dis_loss: 0.45297789573669434\n","tensor(0.3103, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4512, device='cuda:0', grad_fn=<AddBackward0>)\n","47th epoch gen_loss: 0.3102869987487793 dis_loss: 0.4512428343296051\n","tensor(0.3104, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4511, device='cuda:0', grad_fn=<AddBackward0>)\n","48th epoch gen_loss: 0.3104427456855774 dis_loss: 0.45113125443458557\n","tensor(0.3114, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4506, device='cuda:0', grad_fn=<AddBackward0>)\n","48th epoch gen_loss: 0.31140241026878357 dis_loss: 0.45056164264678955\n","tensor(0.3116, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4496, device='cuda:0', grad_fn=<AddBackward0>)\n","49th epoch gen_loss: 0.3115690350532532 dis_loss: 0.4496394097805023\n","tensor(0.3123, device='cuda:0', grad_fn=<SumBackward0>) tensor(0.4479, device='cuda:0', grad_fn=<AddBackward0>)\n","49th epoch gen_loss: 0.3123352527618408 dis_loss: 0.44787856936454773\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vqyJSCvxXJ6A","colab_type":"text"},"source":["# Do not expect much on this naive GAN \n","- 네트워크 구조에서 봤듯이 거의 학습이 되지 않습니다.\n","- 여기에 convolution 연산을 추가하면 성능이 올라가는데 이는 DCGAN 코드에서 확인하세요."]},{"cell_type":"code","metadata":{"id":"B2JI92keSOpL","colab_type":"code","outputId":"78fa00fc-16f4-4ec7-d963-8349d48c65a3","executionInfo":{"status":"ok","timestamp":1559570903372,"user_tz":-540,"elapsed":314526,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":10217,"output_embedded_package_id":"1iTu4t4I3MWTRZQfga1IET9nNzc0cgqcH"}},"source":["from glob import glob \n","\n","for i in range(epoch):\n","  print(i)\n","  file_list = glob(\"./result/gen_{}_*.png\".format(i))\n","  img_per_epoch = len(file_list)\n","  for idx,j in enumerate(file_list):\n","    img = plt.imread(j)\n","    plt.subplot(1,img_per_epoch,idx+1)\n","    plt.imshow(img)\n","  plt.show()"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"DqB7bOtVVa7P","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}