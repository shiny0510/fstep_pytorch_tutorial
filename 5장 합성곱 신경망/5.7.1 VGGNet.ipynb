{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5.7.1 VGGNet.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"collapsed":true,"id":"BZiTXRcBHyFo","colab_type":"text"},"source":["# VGGNet Implementation\n","\n","- 컨볼루션 연산만 배운 상태에서 VGG를 바로 이해하고 짜기에는 무리가 있습니다.\n","- 연산들의 동작 원리를 충분히 이해한후 다시 보셔도 늦지 않습니다.\n","\n","- 2014 ILSVRC 2nd place\n","- VGG-16\n","- Convolution layer\n","- Maxpooling layer\n","- Fully connected layer\n","\n","![대체 텍스트](https://qph.fs.quoracdn.net/main-qimg-e657c195fc2696c7d5fc0b1e3682fde6)"]},{"cell_type":"code","metadata":{"id":"Q-C-HidGIaAC","colab_type":"code","outputId":"12387b96-a11f-4d62-e81d-da947ab7c3ce","executionInfo":{"status":"ok","timestamp":1566806141853,"user_tz":-540,"elapsed":7669,"user":{"displayName":"Gunho Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBSqM0cFU5ZceEDo5gH8hXfSGh8z5BVTu5HgREceg=s64","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# 런타임 유형 GPU 모드로 변경\n","!pip install torch torchvision"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Cz9l06K4eVE8","colab_type":"text"},"source":["## Prepare Data\n","\n","- 모델이 학습이 되는지만 확인할 수 있게 간단한 데이터를 다운로드 합니다."]},{"cell_type":"code","metadata":{"id":"xU1Z6btAPFoO","colab_type":"code","outputId":"895c4f86-0703-4764-810a-c2404887f3ec","executionInfo":{"status":"ok","timestamp":1566806185783,"user_tz":-540,"elapsed":22804,"user":{"displayName":"Gunho Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBSqM0cFU5ZceEDo5gH8hXfSGh8z5BVTu5HgREceg=s64","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":782}},"source":["!rm -r images\n","import os \n","\n","# 이미지 파일을 저장할 폴더를 생성합니다.\n","try:\n","  os.mkdir(\"images\")\n","  os.mkdir(\"images/dogs\")\n","  os.mkdir(\"images/cats\")\n","except:\n","  pass\n","\n","# 이미지들을 지정한 위치에 다운로드합니다.\n","# images/dogs 밑에 2개\n","!wget https://i.kinja-img.com/gawker-media/image/upload/s--WFkXeene--/c_scale,f_auto,fl_progressive,q_80,w_800/ol9ceoqxidudap8owlwn.jpg -P images/dogs\n","!wget https://www.rspcansw.org.au/wp-content/uploads/2017/08/50_a-feature_dogs-and-puppies_mobile.jpg -P images/dogs\n","\n","# images/cats 밑에 2개\n","!wget https://www.catster.com/wp-content/uploads/2018/05/A-gray-cat-crying-looking-upset.jpg -P images/cats\n","!wget https://www.scarymommy.com/wp-content/uploads/2018/01/c1.jpg?w=700 -P images/cats"],"execution_count":2,"outputs":[{"output_type":"stream","text":["rm: cannot remove 'images': No such file or directory\n","--2019-08-26 07:56:09--  https://i.kinja-img.com/gawker-media/image/upload/s--WFkXeene--/c_scale,f_auto,fl_progressive,q_80,w_800/ol9ceoqxidudap8owlwn.jpg\n","Resolving i.kinja-img.com (i.kinja-img.com)... 151.101.194.166, 151.101.130.166, 151.101.2.166, ...\n","Connecting to i.kinja-img.com (i.kinja-img.com)|151.101.194.166|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 32099 (31K) [image/jpeg]\n","Saving to: ‘images/dogs/ol9ceoqxidudap8owlwn.jpg’\n","\n","ol9ceoqxidudap8owlw 100%[===================>]  31.35K  --.-KB/s    in 0.005s  \n","\n","2019-08-26 07:56:10 (5.82 MB/s) - ‘images/dogs/ol9ceoqxidudap8owlwn.jpg’ saved [32099/32099]\n","\n","--2019-08-26 07:56:15--  https://www.rspcansw.org.au/wp-content/uploads/2017/08/50_a-feature_dogs-and-puppies_mobile.jpg\n","Resolving www.rspcansw.org.au (www.rspcansw.org.au)... 101.0.77.122\n","Connecting to www.rspcansw.org.au (www.rspcansw.org.au)|101.0.77.122|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 130940 (128K) [image/jpeg]\n","Saving to: ‘images/dogs/50_a-feature_dogs-and-puppies_mobile.jpg’\n","\n","50_a-feature_dogs-a 100%[===================>] 127.87K   157KB/s    in 0.8s    \n","\n","2019-08-26 07:56:17 (157 KB/s) - ‘images/dogs/50_a-feature_dogs-and-puppies_mobile.jpg’ saved [130940/130940]\n","\n","--2019-08-26 07:56:19--  https://www.catster.com/wp-content/uploads/2018/05/A-gray-cat-crying-looking-upset.jpg\n","Resolving www.catster.com (www.catster.com)... 192.124.249.102\n","Connecting to www.catster.com (www.catster.com)|192.124.249.102|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 165145 (161K) [image/jpeg]\n","Saving to: ‘images/cats/A-gray-cat-crying-looking-upset.jpg’\n","\n","A-gray-cat-crying-l 100%[===================>] 161.27K  --.-KB/s    in 0.03s   \n","\n","2019-08-26 07:56:19 (5.12 MB/s) - ‘images/cats/A-gray-cat-crying-looking-upset.jpg’ saved [165145/165145]\n","\n","--2019-08-26 07:56:22--  https://www.scarymommy.com/wp-content/uploads/2018/01/c1.jpg?w=700\n","Resolving www.scarymommy.com (www.scarymommy.com)... 104.18.166.96, 104.18.164.96, 104.18.168.96, ...\n","Connecting to www.scarymommy.com (www.scarymommy.com)|104.18.166.96|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2169547 (2.1M) [image/jpeg]\n","Saving to: ‘images/cats/c1.jpg?w=700’\n","\n","c1.jpg?w=700        100%[===================>]   2.07M  --.-KB/s    in 0.03s   \n","\n","2019-08-26 07:56:23 (67.4 MB/s) - ‘images/cats/c1.jpg?w=700’ saved [2169547/2169547]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"ZELujmpnHyFq","colab_type":"text"},"source":["## 1. Settings\n","### 1) Import required libraries"]},{"cell_type":"code","metadata":{"id":"bqkPfR0oHyFq","colab_type":"code","colab":{}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.init as init\n","import torch.utils.data as data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-umoG8-dHyFw","colab_type":"text"},"source":["### 2) Hyperparameter"]},{"cell_type":"code","metadata":{"id":"tahoG-3cHyFx","colab_type":"code","colab":{}},"source":["batch_size= 1\n","learning_rate = 0.0002\n","num_epoch = 100"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vgvQYlzOHyFz","colab_type":"text"},"source":["## 2. Data Loader\n","\n","- https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=imagefolder#torchvision.datasets.ImageFolder\n","- ImageFolder라는 함수를 이용해 따로 이미지-라벨 쌍을 만들지 않고 폴더에 저장하는것만으로 쉽게 이미지-라벨 쌍을 만들 수 있습니다.\n","\n","ex)\n","\n","root/dog/xxx.png\n","\n","root/dog/xxy.png\n","\n","root/cat/123.png\n","\n","root/cat/nsdf3.png\n","\n","                    "]},{"cell_type":"code","metadata":{"id":"jWItBFtRJ_Rx","colab_type":"code","colab":{}},"source":["# 라벨(혹은 클래스) 별로 폴더가 저장되어 있는 루트 디렉토리를 지정합니다.\n","img_dir = \"./images\"\n","\n","# 해당 루트 디렉토리를 ImageFolder 함수에 전달합니다.\n","# 이때 이미지들에 대한 변형도 같이 전달해줍니다.\n","img_data = dset.ImageFolder(img_dir, transforms.Compose([\n","                                      transforms.Resize(256),                   # 이미지 크기를 256x256으로 바꿔줍니다.\n","                                      transforms.RandomResizedCrop(224),        # 256x256 이미지의 랜덤한 위치에서 224x224 크기만큼 샘플링 합니다.\n","                                      transforms.RandomHorizontalFlip(),        # 랜덤한 확률로 이미지를 좌우반전 합니다.\n","                                      transforms.ToTensor(),                    # 이미지 데이터를 텐서로 변형합니다.\n","            ]))\n","\n","train_loader = data.DataLoader(img_data, batch_size=batch_size,\n","                            shuffle=True, num_workers=2)\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CABXOGJxHyF4","colab_type":"text"},"source":["## 3. Model \n","### 1) Basic Blocks\n","\n","- 모델에 반복되는 부분이 많기 때문에 이를 함수로 만들어 단순화 합니다.\n","- 맨 위에 이미지를 보면 컨볼루션 연산이 2번 연속하는 경우와 3번 연속하는 경우가 있는데 이를 각각 만들어줍니다.\n","- 아래의 코드는 최적의 방법이라기 보다는 그림의 구조를 모방한 코드입니다. "]},{"cell_type":"code","metadata":{"id":"3EOMiN5iHyF5","colab_type":"code","colab":{}},"source":["# 컨볼루션 연산이 2번 연속하는 경우\n","# 컨볼루션-활성화함수-컨볼루션-활성화함수-풀링\n","def conv_2_block(in_dim,out_dim):\n","    model = nn.Sequential(\n","        nn.Conv2d(in_dim,out_dim,kernel_size=3,padding=1),\n","        nn.ReLU(),\n","        nn.Conv2d(out_dim,out_dim,kernel_size=3,padding=1),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2,2)\n","    )\n","    return model\n","\n","  \n","# 컨볼루션 연산이 3번 연속하는 경우\n","# 컨볼루션-활성화함수-컨볼루션-활성화함수-컨볼루션-활성화함수-풀링\n","def conv_3_block(in_dim,out_dim):\n","    model = nn.Sequential(\n","        nn.Conv2d(in_dim,out_dim,kernel_size=3,padding=1),\n","        nn.ReLU(),\n","        nn.Conv2d(out_dim,out_dim,kernel_size=3,padding=1),\n","        nn.ReLU(),\n","        nn.Conv2d(out_dim,out_dim,kernel_size=3,padding=1),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2,2)\n","    )\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EoDJbUUVHyF8","colab_type":"text"},"source":["### 2) VGG Model"]},{"cell_type":"code","metadata":{"id":"3pSEy-S7HyF9","colab_type":"code","colab":{}},"source":["# 위에서 정의한 블록들을 이용해 VGG 네트워크를 만들어보겠습니다.\n","# 필터의 개수가 2의 n승의 값을 가지기 때문에 base_dim이란 변수를 추가해서 단순화 했습니다.\n","# 현재 dog, cat 두 가지 클래스를 구분하려고 하기 때문에 num_classes=2로 설정했습니다.\n","\n","class VGG(nn.Module):\n","    def __init__(self, base_dim, num_classes=2):\n","        super(VGG, self).__init__()\n","        self.feature = nn.Sequential(\n","            conv_2_block(3,base_dim),\n","            conv_2_block(base_dim,2*base_dim),\n","            conv_3_block(2*base_dim,4*base_dim),\n","            conv_3_block(4*base_dim,8*base_dim),\n","            conv_3_block(8*base_dim,8*base_dim),            \n","        )\n","        self.fc_layer = nn.Sequential(\n","            nn.Linear(8*base_dim * 7 * 7, 100),\n","            nn.ReLU(True),                                                      # True 는 inplace 연산을 하겠다는 의미를 가집니다. inplace 연산은 결과값을 새로운 변수에 값을 저장하는 대신 기존의 데이터를 대체하는것을 의미합니다.\n","            #nn.Dropout(),\n","            nn.Linear(100, 20),\n","            nn.ReLU(True),\n","            #nn.Dropout(),\n","            nn.Linear(20, num_classes),\n","        )\n","\n","    def forward(self, x):\n","        x = self.feature(x)\n","        x = x.view(x.size(0), -1)                                               # x.size(0)를 batch size로 바꿔도 같은 값입니다.\n","        x = self.fc_layer(x)\n","        return x\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YsdmlK82HyGC","colab_type":"text"},"source":["## 4. Optimizer & Loss"]},{"cell_type":"code","metadata":{"id":"lFpmR6WZHyGC","colab_type":"code","outputId":"9a9acdb7-7085-4a93-fe60-2aeb720ecc0f","executionInfo":{"status":"ok","timestamp":1566806408687,"user_tz":-540,"elapsed":6817,"user":{"displayName":"Gunho Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBSqM0cFU5ZceEDo5gH8hXfSGh8z5BVTu5HgREceg=s64","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":884}},"source":["# gpu가 사용 가능한 경우에는 device를 0번 gpu로 설정하고 불가능하면 cpu로 설정합니다.\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","\n","# 앞서 정의한대로 vGG 클래스를 인스턴스화 하고 지정한 장치에 올립니다.\n","model = VGG(base_dim=16).to(device)\n","\n","# 손실함수 및 최적화함수를 설정합니다.\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# 모델 자녀 노드의 이름과 모듈을 출력합니다.\n","for i in model.named_children():\n","    print(i)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["cuda:0\n","('feature', Sequential(\n","  (0): Sequential(\n","    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU()\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (1): Sequential(\n","    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU()\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (2): Sequential(\n","    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU()\n","    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (3): Sequential(\n","    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU()\n","    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (4): Sequential(\n","    (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU()\n","    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU()\n","    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (5): ReLU()\n","    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","))\n","('fc_layer', Sequential(\n","  (0): Linear(in_features=6272, out_features=100, bias=True)\n","  (1): ReLU(inplace)\n","  (2): Linear(in_features=100, out_features=20, bias=True)\n","  (3): ReLU(inplace)\n","  (4): Linear(in_features=20, out_features=2, bias=True)\n","))\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KuUHPn3AHyGG","colab_type":"text"},"source":["## 5. Train"]},{"cell_type":"code","metadata":{"id":"YvzZt_LDHyGH","colab_type":"code","outputId":"bde7cc5e-c233-40a0-8050-c2f811e68d99","executionInfo":{"status":"ok","timestamp":1566806466569,"user_tz":-540,"elapsed":20357,"user":{"displayName":"Gunho Choi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBSqM0cFU5ZceEDo5gH8hXfSGh8z5BVTu5HgREceg=s64","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["for i in range(num_epoch):\n","    for j,[image,label] in enumerate(train_loader):\n","        x = image.to(device)\n","        y_= label.to(device)\n","        \n","        optimizer.zero_grad()\n","        output = model.forward(x)\n","        loss = loss_func(output,y_)\n","        loss.backward()\n","        optimizer.step()\n","\n","    if i % 10 ==0:\n","        print(loss)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["tensor(0.6225, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.6045, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.5143, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.4301, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.4345, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.4101, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.4734, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.4204, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(0.6140, device='cuda:0', grad_fn=<NllLossBackward>)\n","tensor(1.0608, device='cuda:0', grad_fn=<NllLossBackward>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e7mTMVQfc14g","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}