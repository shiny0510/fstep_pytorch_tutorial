{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[참고]Char_RNN_GRU_리눅스코드 생성.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1LEMD4f9dG3U","colab_type":"text"},"source":["# Character Recurrent Neural Network\n","- mimicing Shakespeare's writing style\n","- Naive RNN"]},{"cell_type":"code","metadata":{"id":"ODxhI-YBeYKz","colab_type":"code","outputId":"ce716e54-acc0-40e1-d04f-33bf670cc3d0","executionInfo":{"status":"ok","timestamp":1559555773673,"user_tz":-540,"elapsed":4497,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["!rm -r data\n","import os \n","\n","try:\n","  os.mkdir(\"./data\")\n","except:\n","  pass\n","\n","!wget https://raw.githubusercontent.com/GunhoChoi/PyTorch-FastCampus/master/05_RNN/2_Char_RNN/data/linux.txt -P ./data"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2019-06-03 09:56:14--  https://raw.githubusercontent.com/GunhoChoi/PyTorch-FastCampus/master/05_RNN/2_Char_RNN/data/linux.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 33756 (33K) [text/plain]\n","Saving to: ‘./data/linux.txt’\n","\n","\rlinux.txt             0%[                    ]       0  --.-KB/s               \rlinux.txt           100%[===================>]  32.96K  --.-KB/s    in 0.01s   \n","\n","2019-06-03 09:56:15 (2.62 MB/s) - ‘./data/linux.txt’ saved [33756/33756]\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"X0FyjLatdG3V","colab_type":"text"},"source":["## 1. Settings\n","### 1) Import required libraries"]},{"cell_type":"code","metadata":{"id":"VVeUr2FjdG3X","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TwWbv_-KdG3a","colab_type":"code","colab":{}},"source":["import unidecode\n","import string\n","import random\n","import re\n","import time, math"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"62S5HbY2dG3d","colab_type":"text"},"source":["## 2) Hyperparameter"]},{"cell_type":"code","metadata":{"id":"oVeZybezdG3e","colab_type":"code","colab":{}},"source":["num_epochs = 2000\n","print_every = 100\n","plot_every = 10\n","chunk_len = 200\n","hidden_size = 100\n","batch_size = 1\n","num_layers = 1\n","embedding_size = 70\n","lr = 0.002"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_eKGWH4BdG3h","colab_type":"text"},"source":["## 2. Data\n","### 1) Prepare characters"]},{"cell_type":"code","metadata":{"id":"2Cg5-Wp0dG3i","colab_type":"code","outputId":"096340c6-5d7b-4052-9e13-fa4832ba8cc9","executionInfo":{"status":"ok","timestamp":1559555774317,"user_tz":-540,"elapsed":5120,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["all_characters = string.printable\n","n_characters = len(all_characters)\n","print(all_characters)\n","print('num_chars = ', n_characters)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n","\r\u000b\f\n","num_chars =  100\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AxeLPVWsdG3m","colab_type":"text"},"source":["### 2) Get text data"]},{"cell_type":"code","metadata":{"id":"5LEkE0bxdG3n","colab_type":"code","outputId":"0cc4bdfd-ca9f-4d1e-acba-cda20b40dec3","executionInfo":{"status":"ok","timestamp":1559555774318,"user_tz":-540,"elapsed":5093,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["file = unidecode.unidecode(open('./data/linux.txt').read())\n","file_len = len(file)\n","print('file_len =', file_len)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["file_len = 33756\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xmTf-IBOdG3r","colab_type":"text"},"source":["## 3. Functions for text processing\n","### 1) Random Chunk"]},{"cell_type":"code","metadata":{"id":"bXDt_MmzdG3s","colab_type":"code","outputId":"2d5ecd26-2dc3-4302-fd0c-963cfe376bf6","executionInfo":{"status":"ok","timestamp":1559555774319,"user_tz":-540,"elapsed":5081,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["def random_chunk():\n","    start_index = random.randint(0, file_len - chunk_len)\n","    end_index = start_index + chunk_len + 1\n","    return file[start_index:end_index]\n","\n","print(random_chunk())"],"execution_count":7,"outputs":[{"output_type":"stream","text":["e\",\n","\t\t.private = offsetof(struct bfq_group, stats.time),\n","\t\t.seq_show = bfqg_print_stat_recursive,\n","\t},\n","\t{\n","\t\t.name = \"bfq.sectors_recursive\",\n","\t\t.seq_show = bfqg_print_stat_sectors_recursive,\n","\t},\n","\t{\n","\t\t.na\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DsSgzWIRdG3v","colab_type":"text"},"source":["### 2) Character to tensor"]},{"cell_type":"code","metadata":{"id":"fhY5WxwsdG3v","colab_type":"code","outputId":"00c4759e-4334-4a99-8fe6-f404fb2f52e4","executionInfo":{"status":"ok","timestamp":1559555774320,"user_tz":-540,"elapsed":5071,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def char_tensor(string):\n","    tensor = torch.zeros(len(string)).long()\n","    for c in range(len(string)):\n","        tensor[c] = all_characters.index(string[c])\n","    return tensor\n","\n","print(char_tensor('ABCdef'))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["tensor([36, 37, 38, 13, 14, 15])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Boc9LQimdG3y","colab_type":"text"},"source":["### 3) Chunk into input & label"]},{"cell_type":"code","metadata":{"id":"nDoMmRY2dG3z","colab_type":"code","colab":{}},"source":["def random_training_set():    \n","    chunk = random_chunk()\n","    inp = char_tensor(chunk[:-1])\n","    target = char_tensor(chunk[1:])\n","    return inp, target"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zsHsRxlodG31","colab_type":"text"},"source":["## 3. Model & Optimizer\n","### 1) Model"]},{"cell_type":"code","metadata":{"id":"abZpjt5udG33","colab_type":"code","colab":{}},"source":["class RNN(nn.Module):\n","    def __init__(self, input_size, embedding_size, hidden_size, output_size, num_layers=1):\n","        super(RNN, self).__init__()\n","        self.input_size = input_size\n","        self.embedding_size = embedding_size\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.num_layers = num_layers\n","        \n","        self.encoder = nn.Embedding(self.input_size, self.embedding_size)\n","        self.rnn = nn.GRU(self.embedding_size,self.hidden_size,self.num_layers)\n","        self.decoder = nn.Linear(self.hidden_size, self.output_size)\n","        \n","    \n","    def forward(self, input, hidden):\n","        out = self.encoder(input.view(1,-1))\n","        out,hidden = self.rnn(out,hidden)\n","        out = self.decoder(out.view(batch_size,-1))\n","        return out,hidden\n","\n","    def init_hidden(self):\n","        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n","        return hidden\n","    \n","model = RNN(n_characters, embedding_size, hidden_size, n_characters, num_layers)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rOVPmyxodG37","colab_type":"code","outputId":"49e30928-095f-4ade-c137-a9525276994e","executionInfo":{"status":"ok","timestamp":1559555774325,"user_tz":-540,"elapsed":5063,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["inp = char_tensor(\"A\")\n","print(inp)\n","hidden = model.init_hidden()\n","print(hidden.size())\n","\n","out,hidden = model(inp,hidden)\n","print(out.size())"],"execution_count":11,"outputs":[{"output_type":"stream","text":["tensor([36])\n","torch.Size([1, 1, 100])\n","torch.Size([1, 100])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yfpAh13edG3_","colab_type":"text"},"source":["### 2) Loss & Optimizer"]},{"cell_type":"code","metadata":{"id":"8wRW02JXdG3_","colab_type":"code","colab":{}},"source":["optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","loss_func = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hoiLqf3_dG4C","colab_type":"text"},"source":["### 3) Test function"]},{"cell_type":"code","metadata":{"id":"rVTQky8vdG4D","colab_type":"code","colab":{}},"source":["def test():\n","    start_str = \"b\"\n","    inp = char_tensor(start_str)\n","    hidden = model.init_hidden()\n","    x = inp\n","\n","    print(start_str,end=\"\")\n","    for i in range(200):\n","        output,hidden = model(x,hidden)\n","\n","        output_dist = output.data.view(-1).div(0.8).exp()\n","        top_i = torch.multinomial(output_dist, 1)[0]\n","        predicted_char = all_characters[top_i]\n","\n","        print(predicted_char,end=\"\")\n","\n","        x = char_tensor(predicted_char)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JNaIweaudG4G","colab_type":"text"},"source":["## 4. Train"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"6CnV3_andG4H","colab_type":"code","outputId":"9e4681f5-2ecf-4439-9b0b-42c034933c92","executionInfo":{"status":"ok","timestamp":1559556067982,"user_tz":-540,"elapsed":298689,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":3641}},"source":["for i in range(num_epochs):\n","    inp,label = random_training_set()\n","    hidden = model.init_hidden()\n","\n","    loss = torch.tensor([0]).type(torch.FloatTensor)\n","    optimizer.zero_grad()\n","    for j in range(chunk_len-1):\n","        x  = inp[j]\n","        y_ = label[j].unsqueeze(0).type(torch.LongTensor)\n","        y,hidden = model(x,hidden)\n","        loss += loss_func(y,y_)\n","\n","    loss.backward()\n","    optimizer.step()\n","    \n","    if i % 100 == 0:\n","        print(\"\\n\",loss/chunk_len,\"\\n\")\n","        test()\n","        print(\"\\n\",\"=\"*100)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["\n"," tensor([4.5848], grad_fn=<DivBackward0>) \n","\n","b,KQfAgcw1'8;(\\`8!Z@q/;OZk9pNMYrAu\n","66v@0l 'Bvak~-=N|vx\">x\\h3u\r0)\\X+m0dI36m`L\n","^F#jV:BST9\u000b`c:4r6ljA//(CW,4K]8}&8j\tfj^\rn|Fq2tBRB:2B@<w )06,zy38-wQ(\\8hc`NCr\\73Min@=\\im-rRSB^lRb#U Ev@tKEzhz$P1$e,g^M)8JVaFxp\n"," ====================================================================================================\n","\n"," tensor([2.4355], grad_fn=<DivBackward0>) \n","\n","blkg &of (s->sstigibfqqg_rf->ogrond bfqg>aue & ing ohe (ned thtnty *a bfqg ne tablg.  lee bfq_stue *tee ist a\t\t\t * fh o#no et, int bfqqgeuitap dntity)\n","{\n","\t\t\t\t\t\t\t\t\t\t} bfq_eimeapityonth  s to tbfqgrethtit\n"," ====================================================================================================\n","\n"," tensor([2.1628], grad_fn=<DivBackward0>) \n","\n","blkcg_prhe me_tat_rew, blkq_s(&nd(bfqg)\n","\n","\t * stats->et;\n","\t * se tatred_restturuit);\n","\tbfqg) {s->princs_wBentite))lime se (stat old *bfqg_ind T= falitice *bfqq_uproup we of prine_bfqg, bfqg, !entity){\n","\t\ty\n"," ====================================================================================================\n","\n"," tensor([1.8952], grad_fn=<DivBackward0>) \n","\n","bfqq = bfqg->encss_stat_clolkg(start_qup *bfqq_group =/\n","\t\t\t\t\t\t\t\t / struct bfq_group(struct clonc_bfq_group *blkg_statsic_tatic bfq_group *bfq_group, Thed assty_entity = blkg_daet_mpreat_stat_tornw, the\n"," ====================================================================================================\n","\n"," tensor([1.9491], grad_fn=<DivBackward0>) \n","\n","bfqg_stats->stats);\n","\t\t\tbfqg_data *sed = of bfq_group *bfqq_data *bfqg = &bfqg to meqg = bfq_group_sturt = bfqg->stat_prio_stats_cllackig, gesursecurss, foro_dalg_data *s->blkg->sched_data_structs(stats\n"," ====================================================================================================\n","\n"," tensor([0.8923], grad_fn=<DivBackward0>) \n","\n","bfqg) stats it maup %hinct becy\n"," * lock cherium the ofprio_restats_pore morent ile = 0;\n","}\n","\n","statsel csive stats ber in bfqg_stats anclurent blkg_size = bfqg_stats_upe.w(struct bfqg_to_bfqg_printht io Ma\n"," ====================================================================================================\n","\n"," tensor([1.5306], grad_fn=<DivBackward0>) \n","\n","bfq.\n","\t\t\t\t\t      se con it bfq_io_size_show, parent(bfqg->torive_trivate_entity_entity_entity = bfq_amyne_entity;\n","\tentity(stats);\n","\tentity->entity);\n","\tbfq_prime);\n","};\n","}\n","\n","void bfqg, stats->group_bfqq_blkg_b\n"," ====================================================================================================\n","\n"," tensor([1.6940], grad_fn=<DivBackward0>) \n","\n","bjeq_seight {,\n","\t\t6f (f)\n","{\n","\tbfqg(bfqd_uporoment_aux([pwat = blkg_print_stat_init(sf,\n","\t\t.namp = bfqq_io_show = uelack, bfqq) {\n","},\n","\t\tprivate = bfq_group *bfqg, fistroot stats);\n","\n","\treturn 0;\n","\n","\tif loke_afqd(\n"," ====================================================================================================\n","\n"," tensor([1.1762], grad_fn=<DivBackward0>) \n","\n","bfqg);\n","\treturn hee *sh->blkg_queue_size(struct bfq_group *bfqg)\n","{\n","\tblkg *bfqg);\n","\tblkg_print_stat_recursive_stats_canclude *s bfq.io_print == bfqg_print_luctive,\n","\t\t.pof(struct bfqg_stats_cgroup *blkg_st\n"," ====================================================================================================\n","\n"," tensor([1.7709], grad_fn=<DivBackward0>) \n","\n","bfqg);\n","}\n","\n","void bfqg->ret(&stats->stat_add(&bfqg, bfqd->root_group(walloc_NFLAG_FISn_bfqg_to_bfqg(bfqg);\n","}\n","{\n","\treturn bfqg_prigrt_bfqd, pration _fio_cpd(velic _bfqq_group *bfqd, blkg_to_bfqq(entity->nhee\n"," ====================================================================================================\n","\n"," tensor([0.9089], grad_fn=<DivBackward0>) \n","\n","blkg_prfill_stoichis of the sius, &bfqg->avg_to_bfqg_move,\n","\t\t.name = bfqg_prentint_blkg_print_writime);\n","\tblkg_rwstat_recursive,\n","\t{\n","\t\t.prequesentern for no flags\n","\t\t * blkg_resaved,\n","\t.private, statio to \n"," ====================================================================================================\n","\n"," tensor([1.6995], grad_fn=<DivBackward0>) \n","\n","blkg_rwstat_group;\n","}\n","\n","void bfq_group *bfqd->root_group *bfqg *pd->lock_log_group *bfqq = bfqg_stats_stats_update_idle_time)))\n","\t\t\tblkcg_policy_bfq.io_cud_group *bfqg = offer u64 bfqq_root_print_aux(&sta\n"," ====================================================================================================\n","\n"," tensor([1.3504], grad_fn=<DivBackward0>) \n","\n","blkg_group_liack_weight = blkg_prof, to *bfqg_print_stat_recursive\",\n","\t\t.private = = \"bfqng);\n","\n","\tentity;\n","\tentity->sched_to_bfq_end_exit(&stats->idle_time),\n","\t\t.seq_shoid_to_bfqg_print Tolis = bfq_entity(e\n"," ====================================================================================================\n","\n"," tensor([1.0711], grad_fn=<DivBackward0>) \n","\n","blkg);\n","\treturn;\n","\tstruct bfq_queue *bfqd->incloct_stat_reset_dellack entity *entity to move to blkg = bfqg_print_rwstat_service blkg_rwstat_to_blkg(pd),\n","\t\t.\n","\t\t\t\t\t\t\t     * The u64 bfq_group, stats->eset(\n"," ====================================================================================================\n","\n"," tensor([1.2710], grad_fn=<DivBackward0>) \n","\n","bfqg->sched_data = &bfqd->in_seq_show = bfqg_print_rwstat_init(&stats->folloci_entity);\n","\tblkg_stat_active_recursive,\n","\t\t.namp = pof,\n","\t\t.\n","\t * blkg_rwstat_logs (is = \"bfq.io_blkgs(sf, gfp);\n","}\n","\n","static void\n"," ====================================================================================================\n","\n"," tensor([0.4265], grad_fn=<DivBackward0>) \n","\n","blkcg_policy_bfq, NULL;\n","\n","\treturn NULL);\n","\tblkg;\n","}\n","\n","struct blkg_rwstat_init(&stats->data *bfqg;\n","}\n","\n","void bfq_end_wr_arent,\n","\t{\n","\t\t.prime(bfqg);\n","\t\trFu_stats->arequeue);\n","\tblkg_leach_change_pd_set_ireed */\n","\tbl\n"," ====================================================================================================\n","\n"," tensor([0.9161], grad_fn=<DivBackward0>) \n","\n","bytes);\n","\t}\n","\tstruct bfq_group *bfqd->idle_time(struct bfq_group *bfqg = bfq_print_rwstat_repare_time);\n","\t\tblkg_rwstat_add(&bfqg->stats);\n","\n","\troot group *blkcg = bfqg(blkg);\n","\t\t\t\t\t\t\t\t\t\t\t\\\n","\n","static void bfq_gr\n"," ====================================================================================================\n","\n"," tensor([0.5478], grad_fn=<DivBackward0>) \n","\n","blkcg_policy_datat = \"bfq.enit(&stats->merged_weight = offsetof(struct bfq_cilall_stat,\n","}\n","\n","/**\n"," * bfq_io_set_time),\n","\t\t.seq_show = bfq_end_weight \"bfq_no_blkcg_print_rwstat_add_aux(&to->get(bfqd->entity\n"," ====================================================================================================\n","\n"," tensor([0.4530], grad_fn=<DivBackward0>) \n","\n","blkg_to_bfqg(pd);\n","}\n","\n","void bfqg_stats_update_group_data *bfqg, unsigned int op)\n","{\n","\tstruct bfq_data *bfqg, unsigned int op)\n","{\n","\tblkg_rwstat_init(&stats->blkg_get of the\n","\t * pinre cosetofely with new_weelo\n"," ====================================================================================================\n","\n"," tensor([1.0063], grad_fn=<DivBackward0>) \n","\n","blkcg)\n","\t\tbfq_entity;\n","\tentity->new_weight\",\n","\t\t\t\t\t\t\t  ctats.\n","entive alserencgs\n","\t\t\t\t\t * stats ->mertorecter of the the parent,\n","\t\t\t\t\t\t     blkg_rwstat_exit(&stats->wait_time(struct bfq_group. */\n","#inc_ct(sf\n"," ====================================================================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SV7mBpxtjJsy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}