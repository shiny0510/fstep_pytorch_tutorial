{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1_Char_LSTM.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"ShSWYFSlENxq","colab_type":"code","colab":{}},"source":["# Simple Character LSTM\n","# Char RNN에서 설명한 부분은 생략했습니다.\n","\n","import torch \n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jPTxJL3qENxu","colab_type":"code","outputId":"bc058c22-4b09-4a0e-f46f-7e05a51136b0","executionInfo":{"status":"ok","timestamp":1559548279205,"user_tz":-540,"elapsed":815,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Preprocessing string data\n","# alphabet(0-25), space(26),..., start, end \n","\n","string = \"hello pytorch. how long can a rnn cell remember? show me your limit!\"\n","chars = \"abcdefghijklmnopqrstuvwxyz ?!.,:;01\"\n","char_list = [i for i in chars]\n","char_len = len(char_list)\n","\n","char_len"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["35"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"h-xqHFGdENx0","colab_type":"code","colab":{}},"source":["# String to onehot vector\n","# a -> [1 0 0 ... 0 0]\n","\n","def string_to_onehot(string):\n","    start = np.zeros(shape=char_len ,dtype=int)\n","    end = np.zeros(shape=char_len ,dtype=int)\n","    start[-2] = 1\n","    end[-1] = 1\n","    for i in string:\n","        idx = char_list.index(i)\n","        zero = np.zeros(shape=char_len ,dtype=int)\n","        zero[idx]=1\n","        start = np.vstack([start,zero])\n","    output = np.vstack([start,end])\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k_gqctcyENx3","colab_type":"code","colab":{}},"source":["# Onehot vector to word\n","# [1 0 0 ... 0 0] -> a \n","\n","def onehot_to_word(onehot_1):\n","    onehot = torch.Tensor.numpy(onehot_1)\n","    return char_list[onehot.argmax()]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gjb-I6DlENx6","colab_type":"code","outputId":"839a9b8e-20c8-47c7-d7ef-e5f0eb783f2d","executionInfo":{"status":"ok","timestamp":1559548279513,"user_tz":-540,"elapsed":1088,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# 하이퍼파라미터 설정\n","# 문자열을 단어 하나씩 잘러서 사용하는걸로 구현해서 batch_size 1로 고정입니다.\n","# batch_size가 1보다 큰 경우는 다음 실습코드에 있습니다.\n","batch_size = 1\n","\n","# seq_len는 바꿔도 학습은 되지만 테스트시 편의성을 위해 1로 설정했습니다.\n","seq_len = 1\n","\n","# num_layers는 입력 형식에만 맞게 형태를 바꿔주면 됩니다.\n","num_layers = 3\n","input_size = char_len\n","hidden_size = 35 \n","lr = 0.01\n","num_epochs = 1000\n","\n","one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor())\n","\n","print(one_hot.size())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["torch.Size([70, 35])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mGTtv6T5ENx9","colab_type":"code","colab":{}},"source":["# RNN with 1 hidden layer\n","\n","class RNN(nn.Module):\n","    def __init__(self, input_size, hidden_size,num_layers):\n","        super(RNN, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size,hidden_size,num_layers)\n","        \n","    def forward(self,input_,hidden,cell):\n","        output,(hidden,cell) = self.lstm(input_,(hidden,cell))\n","        return output,hidden,cell\n","    \n","    def init_hidden_cell(self):\n","        hidden = torch.zeros(num_layers,batch_size,hidden_size)\n","        cell = torch.zeros(num_layers,batch_size,hidden_size)\n","        return hidden,cell\n","    \n","rnn = RNN(input_size,hidden_size, num_layers)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2Gt2qWjRENyA","colab_type":"code","colab":{}},"source":["# Loss function & Optimizer\n","\n","loss_func = nn.MSELoss()\n","optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U0xJsfTQENyD","colab_type":"code","outputId":"01cada2d-81e5-44fd-99cd-8dc97dfc64b8","executionInfo":{"status":"ok","timestamp":1559548279522,"user_tz":-540,"elapsed":1074,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["j=0\n","input_data = one_hot[j:j+seq_len].view(seq_len, batch_size, input_size)\n","print(input_data.size())\n","\n","hidden,cell = rnn.init_hidden_cell()\n","print(hidden.size(),cell.size())\n","\n","output, hidden,cell = rnn(input_data,hidden,cell)\n","print(output.size(),hidden.size(),cell.size())"],"execution_count":8,"outputs":[{"output_type":"stream","text":["torch.Size([1, 1, 35])\n","torch.Size([3, 1, 35]) torch.Size([3, 1, 35])\n","torch.Size([1, 1, 35]) torch.Size([3, 1, 35]) torch.Size([3, 1, 35])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"92Vh1bteEXKu","colab_type":"code","outputId":"5987a3f3-d37b-4248-9308-8bf2568534f9","executionInfo":{"status":"ok","timestamp":1559548361566,"user_tz":-540,"elapsed":83111,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":1717}},"source":["unroll_len = one_hot.size()[0]//seq_len -1\n","for i in range(num_epochs):\n","    hidden,cell = rnn.init_hidden_cell()\n","    \n","    loss = 0\n","    for j in range(unroll_len):\n","        input_data = one_hot[j:j+seq_len].view(seq_len,batch_size,input_size) \n","        label = one_hot[j+1:j+seq_len+1].view(seq_len,batch_size,input_size)\n","        \n","        optimizer.zero_grad()\n","        \n","        output, hidden, cell = rnn(input_data,hidden,cell)\n","        loss += loss_func(output.view(1,-1),label.view(1,-1))\n","        \n","    loss.backward()\n","    optimizer.step()\n","\n","    if i%10 ==0:\n","        print(loss)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["tensor(2.3169, grad_fn=<AddBackward0>)\n","tensor(1.8134, grad_fn=<AddBackward0>)\n","tensor(1.7129, grad_fn=<AddBackward0>)\n","tensor(1.5591, grad_fn=<AddBackward0>)\n","tensor(1.3444, grad_fn=<AddBackward0>)\n","tensor(1.0239, grad_fn=<AddBackward0>)\n","tensor(0.6340, grad_fn=<AddBackward0>)\n","tensor(0.3646, grad_fn=<AddBackward0>)\n","tensor(0.1904, grad_fn=<AddBackward0>)\n","tensor(0.1131, grad_fn=<AddBackward0>)\n","tensor(0.0634, grad_fn=<AddBackward0>)\n","tensor(0.0410, grad_fn=<AddBackward0>)\n","tensor(0.0288, grad_fn=<AddBackward0>)\n","tensor(0.0228, grad_fn=<AddBackward0>)\n","tensor(0.0195, grad_fn=<AddBackward0>)\n","tensor(0.0174, grad_fn=<AddBackward0>)\n","tensor(0.0155, grad_fn=<AddBackward0>)\n","tensor(0.0144, grad_fn=<AddBackward0>)\n","tensor(0.0134, grad_fn=<AddBackward0>)\n","tensor(0.0125, grad_fn=<AddBackward0>)\n","tensor(0.0115, grad_fn=<AddBackward0>)\n","tensor(0.0104, grad_fn=<AddBackward0>)\n","tensor(0.0093, grad_fn=<AddBackward0>)\n","tensor(0.0086, grad_fn=<AddBackward0>)\n","tensor(0.0082, grad_fn=<AddBackward0>)\n","tensor(0.0079, grad_fn=<AddBackward0>)\n","tensor(0.0077, grad_fn=<AddBackward0>)\n","tensor(0.0072, grad_fn=<AddBackward0>)\n","tensor(0.0070, grad_fn=<AddBackward0>)\n","tensor(0.0068, grad_fn=<AddBackward0>)\n","tensor(0.0066, grad_fn=<AddBackward0>)\n","tensor(0.0065, grad_fn=<AddBackward0>)\n","tensor(0.0072, grad_fn=<AddBackward0>)\n","tensor(0.0064, grad_fn=<AddBackward0>)\n","tensor(0.0063, grad_fn=<AddBackward0>)\n","tensor(0.0061, grad_fn=<AddBackward0>)\n","tensor(0.0060, grad_fn=<AddBackward0>)\n","tensor(0.0059, grad_fn=<AddBackward0>)\n","tensor(0.0059, grad_fn=<AddBackward0>)\n","tensor(0.0058, grad_fn=<AddBackward0>)\n","tensor(0.0057, grad_fn=<AddBackward0>)\n","tensor(0.0057, grad_fn=<AddBackward0>)\n","tensor(0.0056, grad_fn=<AddBackward0>)\n","tensor(0.0056, grad_fn=<AddBackward0>)\n","tensor(0.0056, grad_fn=<AddBackward0>)\n","tensor(0.0056, grad_fn=<AddBackward0>)\n","tensor(0.0055, grad_fn=<AddBackward0>)\n","tensor(0.0054, grad_fn=<AddBackward0>)\n","tensor(0.0054, grad_fn=<AddBackward0>)\n","tensor(0.0054, grad_fn=<AddBackward0>)\n","tensor(0.0059, grad_fn=<AddBackward0>)\n","tensor(0.0055, grad_fn=<AddBackward0>)\n","tensor(0.0052, grad_fn=<AddBackward0>)\n","tensor(0.0046, grad_fn=<AddBackward0>)\n","tensor(0.0045, grad_fn=<AddBackward0>)\n","tensor(0.0039, grad_fn=<AddBackward0>)\n","tensor(0.0030, grad_fn=<AddBackward0>)\n","tensor(0.0026, grad_fn=<AddBackward0>)\n","tensor(0.0025, grad_fn=<AddBackward0>)\n","tensor(0.0025, grad_fn=<AddBackward0>)\n","tensor(0.0024, grad_fn=<AddBackward0>)\n","tensor(0.0024, grad_fn=<AddBackward0>)\n","tensor(0.0024, grad_fn=<AddBackward0>)\n","tensor(0.0023, grad_fn=<AddBackward0>)\n","tensor(0.0023, grad_fn=<AddBackward0>)\n","tensor(0.0023, grad_fn=<AddBackward0>)\n","tensor(0.0023, grad_fn=<AddBackward0>)\n","tensor(0.0023, grad_fn=<AddBackward0>)\n","tensor(0.0022, grad_fn=<AddBackward0>)\n","tensor(0.0022, grad_fn=<AddBackward0>)\n","tensor(0.0022, grad_fn=<AddBackward0>)\n","tensor(0.0022, grad_fn=<AddBackward0>)\n","tensor(0.0026, grad_fn=<AddBackward0>)\n","tensor(0.0025, grad_fn=<AddBackward0>)\n","tensor(0.0022, grad_fn=<AddBackward0>)\n","tensor(0.0022, grad_fn=<AddBackward0>)\n","tensor(0.0022, grad_fn=<AddBackward0>)\n","tensor(0.0021, grad_fn=<AddBackward0>)\n","tensor(0.0021, grad_fn=<AddBackward0>)\n","tensor(0.0021, grad_fn=<AddBackward0>)\n","tensor(0.0021, grad_fn=<AddBackward0>)\n","tensor(0.0021, grad_fn=<AddBackward0>)\n","tensor(0.0021, grad_fn=<AddBackward0>)\n","tensor(0.0021, grad_fn=<AddBackward0>)\n","tensor(0.0021, grad_fn=<AddBackward0>)\n","tensor(0.0021, grad_fn=<AddBackward0>)\n","tensor(0.0021, grad_fn=<AddBackward0>)\n","tensor(0.0020, grad_fn=<AddBackward0>)\n","tensor(0.0020, grad_fn=<AddBackward0>)\n","tensor(0.0020, grad_fn=<AddBackward0>)\n","tensor(0.0020, grad_fn=<AddBackward0>)\n","tensor(0.0020, grad_fn=<AddBackward0>)\n","tensor(0.0020, grad_fn=<AddBackward0>)\n","tensor(0.0020, grad_fn=<AddBackward0>)\n","tensor(0.0025, grad_fn=<AddBackward0>)\n","tensor(0.0022, grad_fn=<AddBackward0>)\n","tensor(0.0020, grad_fn=<AddBackward0>)\n","tensor(0.0020, grad_fn=<AddBackward0>)\n","tensor(0.0020, grad_fn=<AddBackward0>)\n","tensor(0.0020, grad_fn=<AddBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2VJSE-SlENyH","colab_type":"code","outputId":"2f0f2319-198c-4140-c643-9602d87e1610","executionInfo":{"status":"ok","timestamp":1559548361567,"user_tz":-540,"elapsed":83093,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["hidden,cell = rnn.init_hidden_cell()\n","\n","for j in range(unroll_len-1):\n","    input_data = one_hot[j:j+1].view(1,batch_size,hidden_size) \n","    label = one_hot[j+1:j+1+1].view(1,batch_size,hidden_size) \n","    \n","    output, hidden, cell = rnn(input_data,hidden,cell)\n","    print(onehot_to_word(output.data),end=\"\") "],"execution_count":10,"outputs":[{"output_type":"stream","text":["hello pytorch. how long can a rnn cell remember? show me your limit!"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nwG1rY0OTZqn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}