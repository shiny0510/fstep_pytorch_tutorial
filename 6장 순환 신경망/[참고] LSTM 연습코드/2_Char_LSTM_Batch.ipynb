{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_Char_LSTM_Batch.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"1skF3eRZDTPk","colab_type":"code","colab":{}},"source":["# 이번 코드는 Batch_First 모드로 구현했습니다.\n","\n","import torch \n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VjbTqHEvDTPu","colab_type":"code","outputId":"db5d43ec-8473-4d44-e86c-d89e2650e018","executionInfo":{"status":"ok","timestamp":1559549037486,"user_tz":-540,"elapsed":721,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Preprocessing string data\n","# alphabet(0-25), space(26), start(27), end(28) -> 29 chars (0-28)\n","\n","string = \"hello pytorch. how long can a rnn cell remember? show me your limit!\"\n","chars = \"abcdefghijklmnopqrstuvwxyz ?!.,:;01\"\n","char_list = [i for i in chars]\n","char_len = len(char_list)\n","\n","char_len"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["35"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"dHOzcFMJDTP5","colab_type":"code","colab":{}},"source":["# String to onehot vector\n","# a -> [1 0 0 ... 0 0]\n","\n","def string_to_onehot(string):\n","    start = np.zeros(shape=char_len ,dtype=int)\n","    end = np.zeros(shape=char_len ,dtype=int)\n","    start[-2] = 1\n","    end[-1] = 1\n","    for i in string:\n","        idx = char_list.index(i)\n","        zero = np.zeros(shape=char_len ,dtype=int)\n","        zero[idx]=1\n","        start = np.vstack([start,zero])\n","    output = np.vstack([start,end])\n","    return output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cZ4Qiz8SDTP8","colab_type":"code","colab":{}},"source":["# Onehot vector to word\n","# [1 0 0 ... 0 0] -> a \n","\n","def onehot_to_word(onehot_1):\n","    onehot = torch.Tensor.numpy(onehot_1)\n","    return char_list[onehot.argmax()]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Qg3dEcdDTP_","colab_type":"code","outputId":"96766e14-15aa-4192-d421-89b61b40b702","executionInfo":{"status":"ok","timestamp":1559549037737,"user_tz":-540,"elapsed":928,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# 하이퍼파라미터 설정\n","# 이번코드는 배치사이즈가 1보다 큰 경우에 대해 만들었습니다.\n","batch_size = 5\n","\n","# seq_len는 바꿔도 학습은 되지만 테스트시 편의성을 위해 1로 설정했습니다.\n","seq_len = 1\n","\n","# num_layers는 자유롭게 바꿀 수 있습니다.\n","num_layers = 3\n","input_size = char_len\n","hidden_size = 35 \n","lr = 0.01\n","num_epochs = 1000\n","\n","one_hot = torch.from_numpy(string_to_onehot(string)).type_as(torch.FloatTensor())\n","\n","print(one_hot.size())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["torch.Size([70, 35])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MYIumx3bDTQD","colab_type":"code","colab":{}},"source":["# RNN with 1 hidden layer\n","\n","class RNN(nn.Module):\n","    def __init__(self, input_size, hidden_size,num_layers):\n","        super(RNN, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n","        \n","    def forward(self,input,hidden,cell):\n","        output,(hidden,cell) = self.lstm(input,(hidden,cell))\n","        return output,hidden,cell\n","    \n","    def init_hidden_cell(self):\n","        hidden = torch.zeros(num_layers, batch_size, hidden_size)\n","        cell = torch.zeros(num_layers, batch_size, hidden_size)\n","        return hidden,cell\n","    \n","rnn = RNN(input_size,hidden_size, num_layers)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Ik03eJSDTQG","colab_type":"code","colab":{}},"source":["# Loss function & Optimizer\n","\n","loss_func = nn.MSELoss()\n","optimizer = torch.optim.Adam(rnn.parameters(), lr=lr)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"K_QtY_c0DTQJ","colab_type":"code","outputId":"1b47518d-243c-4f41-a793-b062dcaf8fab","executionInfo":{"status":"ok","timestamp":1559549037743,"user_tz":-540,"elapsed":910,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["j=0\n","input_data = one_hot[j:j+batch_size].view(batch_size,seq_len,input_size)\n","print(input_data.size())\n","\n","hidden,cell = rnn.init_hidden_cell()\n","print(hidden.size(),cell.size())\n","\n","output,hidden,cell = rnn(input_data,hidden,cell)\n","print(output.size(),hidden.size(),cell.size())\n","\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["torch.Size([5, 1, 35])\n","torch.Size([3, 5, 35]) torch.Size([3, 5, 35])\n","torch.Size([5, 1, 35]) torch.Size([3, 5, 35]) torch.Size([3, 5, 35])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V71ND6PXD9CM","colab_type":"code","outputId":"e4adb43b-7727-46f2-f926-b923a4d5288a","executionInfo":{"status":"ok","timestamp":1559549118047,"user_tz":-540,"elapsed":81208,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":1717}},"source":["unroll_len = one_hot.size()[0]//seq_len -1\n","for i in range(num_epochs):\n","    optimizer.zero_grad()\n","    hidden,cell = rnn.init_hidden_cell()\n","    \n","    loss = 0\n","    for j in range(unroll_len-batch_size+1):\n","        \n","        # batch size에 맞게 one-hot 벡터를 스택 합니다.\n","        # 예를 들어 batch size가 3이면 pytorch에서 pyt를 one-hot 벡터로 바꿔서 쌓고\n","        # 목표값으로 yto를 one-hot 벡터로 바꿔서 쌓는 과정입니다.\n","        input_data = torch.stack([one_hot[j+k:j+k+seq_len] for k in range(batch_size)],dim=0)\n","        label = torch.stack([one_hot[j+k+1:j+k+seq_len+1] for k in range(batch_size)],dim=0)\n","        \n","        input_data = input_data\n","        label = label\n","        \n","        output, hidden, cell = rnn(input_data,hidden,cell)\n","        loss += loss_func(output.view(1,-1),label.view(1,-1))\n","        \n","    loss.backward()\n","    optimizer.step()\n","\n","    if i % 10 == 0:\n","        print(loss)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["tensor(2.2972, grad_fn=<AddBackward0>)\n","tensor(1.7071, grad_fn=<AddBackward0>)\n","tensor(1.6303, grad_fn=<AddBackward0>)\n","tensor(1.5253, grad_fn=<AddBackward0>)\n","tensor(1.3940, grad_fn=<AddBackward0>)\n","tensor(1.1777, grad_fn=<AddBackward0>)\n","tensor(0.8639, grad_fn=<AddBackward0>)\n","tensor(0.5385, grad_fn=<AddBackward0>)\n","tensor(0.2710, grad_fn=<AddBackward0>)\n","tensor(0.1326, grad_fn=<AddBackward0>)\n","tensor(0.0951, grad_fn=<AddBackward0>)\n","tensor(0.0659, grad_fn=<AddBackward0>)\n","tensor(0.0514, grad_fn=<AddBackward0>)\n","tensor(0.0434, grad_fn=<AddBackward0>)\n","tensor(0.0385, grad_fn=<AddBackward0>)\n","tensor(0.0351, grad_fn=<AddBackward0>)\n","tensor(0.0326, grad_fn=<AddBackward0>)\n","tensor(0.0302, grad_fn=<AddBackward0>)\n","tensor(0.0277, grad_fn=<AddBackward0>)\n","tensor(0.0257, grad_fn=<AddBackward0>)\n","tensor(0.0234, grad_fn=<AddBackward0>)\n","tensor(0.0210, grad_fn=<AddBackward0>)\n","tensor(0.0195, grad_fn=<AddBackward0>)\n","tensor(0.0182, grad_fn=<AddBackward0>)\n","tensor(0.0171, grad_fn=<AddBackward0>)\n","tensor(0.0177, grad_fn=<AddBackward0>)\n","tensor(0.0158, grad_fn=<AddBackward0>)\n","tensor(0.0151, grad_fn=<AddBackward0>)\n","tensor(0.0146, grad_fn=<AddBackward0>)\n","tensor(0.0143, grad_fn=<AddBackward0>)\n","tensor(0.0139, grad_fn=<AddBackward0>)\n","tensor(0.0132, grad_fn=<AddBackward0>)\n","tensor(0.0128, grad_fn=<AddBackward0>)\n","tensor(0.0125, grad_fn=<AddBackward0>)\n","tensor(0.0121, grad_fn=<AddBackward0>)\n","tensor(0.0119, grad_fn=<AddBackward0>)\n","tensor(0.0117, grad_fn=<AddBackward0>)\n","tensor(0.0116, grad_fn=<AddBackward0>)\n","tensor(0.0115, grad_fn=<AddBackward0>)\n","tensor(0.0114, grad_fn=<AddBackward0>)\n","tensor(0.0113, grad_fn=<AddBackward0>)\n","tensor(0.0112, grad_fn=<AddBackward0>)\n","tensor(0.0112, grad_fn=<AddBackward0>)\n","tensor(0.0111, grad_fn=<AddBackward0>)\n","tensor(0.0110, grad_fn=<AddBackward0>)\n","tensor(0.0110, grad_fn=<AddBackward0>)\n","tensor(0.0109, grad_fn=<AddBackward0>)\n","tensor(0.0109, grad_fn=<AddBackward0>)\n","tensor(0.0108, grad_fn=<AddBackward0>)\n","tensor(0.0110, grad_fn=<AddBackward0>)\n","tensor(0.0108, grad_fn=<AddBackward0>)\n","tensor(0.0107, grad_fn=<AddBackward0>)\n","tensor(0.0107, grad_fn=<AddBackward0>)\n","tensor(0.0106, grad_fn=<AddBackward0>)\n","tensor(0.0106, grad_fn=<AddBackward0>)\n","tensor(0.0106, grad_fn=<AddBackward0>)\n","tensor(0.0105, grad_fn=<AddBackward0>)\n","tensor(0.0105, grad_fn=<AddBackward0>)\n","tensor(0.0105, grad_fn=<AddBackward0>)\n","tensor(0.0105, grad_fn=<AddBackward0>)\n","tensor(0.0106, grad_fn=<AddBackward0>)\n","tensor(0.0104, grad_fn=<AddBackward0>)\n","tensor(0.0104, grad_fn=<AddBackward0>)\n","tensor(0.0104, grad_fn=<AddBackward0>)\n","tensor(0.0104, grad_fn=<AddBackward0>)\n","tensor(0.0103, grad_fn=<AddBackward0>)\n","tensor(0.0103, grad_fn=<AddBackward0>)\n","tensor(0.0103, grad_fn=<AddBackward0>)\n","tensor(0.0103, grad_fn=<AddBackward0>)\n","tensor(0.0103, grad_fn=<AddBackward0>)\n","tensor(0.0103, grad_fn=<AddBackward0>)\n","tensor(0.0102, grad_fn=<AddBackward0>)\n","tensor(0.0102, grad_fn=<AddBackward0>)\n","tensor(0.0102, grad_fn=<AddBackward0>)\n","tensor(0.0103, grad_fn=<AddBackward0>)\n","tensor(0.0102, grad_fn=<AddBackward0>)\n","tensor(0.0100, grad_fn=<AddBackward0>)\n","tensor(0.0091, grad_fn=<AddBackward0>)\n","tensor(0.0089, grad_fn=<AddBackward0>)\n","tensor(0.0088, grad_fn=<AddBackward0>)\n","tensor(0.0088, grad_fn=<AddBackward0>)\n","tensor(0.0088, grad_fn=<AddBackward0>)\n","tensor(0.0087, grad_fn=<AddBackward0>)\n","tensor(0.0087, grad_fn=<AddBackward0>)\n","tensor(0.0087, grad_fn=<AddBackward0>)\n","tensor(0.0087, grad_fn=<AddBackward0>)\n","tensor(0.0087, grad_fn=<AddBackward0>)\n","tensor(0.0087, grad_fn=<AddBackward0>)\n","tensor(0.0087, grad_fn=<AddBackward0>)\n","tensor(0.0087, grad_fn=<AddBackward0>)\n","tensor(0.0086, grad_fn=<AddBackward0>)\n","tensor(0.0086, grad_fn=<AddBackward0>)\n","tensor(0.0086, grad_fn=<AddBackward0>)\n","tensor(0.0086, grad_fn=<AddBackward0>)\n","tensor(0.0089, grad_fn=<AddBackward0>)\n","tensor(0.0087, grad_fn=<AddBackward0>)\n","tensor(0.0086, grad_fn=<AddBackward0>)\n","tensor(0.0086, grad_fn=<AddBackward0>)\n","tensor(0.0086, grad_fn=<AddBackward0>)\n","tensor(0.0086, grad_fn=<AddBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LyafHep4DTQP","colab_type":"code","outputId":"ab4ce432-7817-4ff0-870d-14423d432f75","executionInfo":{"status":"ok","timestamp":1559552063939,"user_tz":-540,"elapsed":822,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["hidden,cell = rnn.init_hidden_cell()\n","\n","for j in range(unroll_len-batch_size+1):\n","    input_data = torch.stack([one_hot[j+k:j+k+seq_len] for k in range(batch_size)],dim=0)\n","    label = torch.stack([one_hot[j+k+1:j+k+seq_len+1] for k in range(batch_size)],dim=0)\n","\n","    input_data = input_data\n","    label = label\n","    \n","    output, hidden, cell = rnn(input_data,hidden,cell)\n","    for k in range(batch_size):\n","        print(onehot_to_word(output[k].data),end=\"\")\n","        if j < unroll_len-batch_size:\n","            break\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["helllello llo plo pyo pyt pytopytorytorctorchorch.rch. ch. hh. ho. how how how low low lon longlong ong cng cag can can can aan a n a r a rna rnn rnn rnn cnn cen cel cellcell ell rll rel rem remeremememembmembeembermber?ber? er? sr? sh? sho showshow how mow mew me  me yme yoe you youryour our lur lir lim limilimitimit!mit!1"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pwQHzX-gEIoD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}