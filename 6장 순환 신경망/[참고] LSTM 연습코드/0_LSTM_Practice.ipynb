{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0_LSTM_Practice.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"3_14gXaT9gN-","colab_type":"text"},"source":["# LSTM Practice\n","## 1) Import required libraries"]},{"cell_type":"code","metadata":{"id":"5YflIP-G9n2L","colab_type":"code","outputId":"f2b4bb98-c03d-43b0-a5fb-121f2bd245fa","executionInfo":{"status":"ok","timestamp":1559546120291,"user_tz":-540,"elapsed":5933,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["!pip install torch torchvision"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.1.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pbSmqYOX9gOA","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GtAGFi5m9gOE","colab_type":"text"},"source":["### 2) Example"]},{"cell_type":"code","metadata":{"id":"0lfCkLo_9gOE","colab_type":"code","outputId":"1c42ced1-3c14-4a3d-99d5-23fe1369b21a","executionInfo":{"status":"ok","timestamp":1559546120589,"user_tz":-540,"elapsed":6201,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM\n","# input_size:     입력의 특성 개수\n","# hidden_size:    hidden state의 특성 개수\n","# num_layers:     LSTM을 몇층으로 쌓을것인가 여부\n","# bias:           편차의 사용 여부\n","# batch_first:    사용하면 입력과 출력의 형태가 [batch, seq, feature]\n","# dropout:        드롭아웃 사용여부\n","# bidirectional:  참고 http://solarisailab.com/archives/1515\n","\n","rnn = nn.LSTM(input_size=3, hidden_size=5, num_layers=2)\n","\n","# 기본적으로 입력의 형태는 (seq_len, batch, input_size)를 따릅니다.\n","input_ = torch.randn(5, 3, 3)\n","\n","# hidden state, cell state의 형태는 (num_layers * num_directions, batch, hidden_size)를 따릅니다.\n","h0 = torch.randn(2, 3, 5)\n","c0 = torch.randn(2, 3, 5)\n","\n","# LSTM에 입력을 전달할때는 input, (h_0, c_0) 처럼 상태를 튜플로 묶어서 전달합니다.\n","output, (hidden_state, cell_state) = rnn(input_, (h0, c0))\n","\n","print(output.size(),hidden_state.size(),cell_state.size())"],"execution_count":3,"outputs":[{"output_type":"stream","text":["torch.Size([5, 3, 5]) torch.Size([2, 3, 5]) torch.Size([2, 3, 5])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rRvJjx6y9gOH","colab_type":"text"},"source":["### 3) Hard coding"]},{"cell_type":"code","metadata":{"id":"VPl8F-o79gOI","colab_type":"code","outputId":"83e1976a-e68c-4e32-f7bf-20796c44e9f0","executionInfo":{"status":"ok","timestamp":1559546120590,"user_tz":-540,"elapsed":6170,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# 이번엔 batch_first를 한번 사용해보겠습니다.\n","# \n","\n","rnn = nn.LSTM(3, 5, 2, batch_first=True)\n","\n","# batch_first를 사용하면 입력의 형태는 (batch, seq, feature)로 받게 됩니다.\n","input_ = torch.randn(3, 5, 3)\n","\n","# hidden state, cell state의 형태는 동일하게 (num_layers * num_directions, batch, hidden_size)를 따릅니다.\n","h0 = torch.randn(2, 3, 5)\n","c0 = torch.randn(2, 3, 5)\n","\n","# LSTM에 입력을 전달할때는 동일하게 input, (h_0, c_0) 처럼 상태를 튜플로 묶어서 전달합니다.\n","output, (hidden_state, cell_state) = rnn(input_, (h0, c0))\n","\n","print(input_.size(),h0.size(),c0.size())\n","print(output.size(),hidden_state.size(),cell_state.size())"],"execution_count":4,"outputs":[{"output_type":"stream","text":["torch.Size([3, 5, 3]) torch.Size([2, 3, 5]) torch.Size([2, 3, 5])\n","torch.Size([3, 5, 5]) torch.Size([2, 3, 5]) torch.Size([2, 3, 5])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UYvfFCG89gON","colab_type":"text"},"source":["### 4) With parameters"]},{"cell_type":"code","metadata":{"id":"Up0HgvEV9gON","colab_type":"code","outputId":"ffbb77a4-63b2-4156-b29a-dc8eaedbc168","executionInfo":{"status":"ok","timestamp":1559546120591,"user_tz":-540,"elapsed":6156,"user":{"displayName":"Choi Gunho","photoUrl":"","userId":"04388737836176863066"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# 숫자로 하드코딩하는건 안 좋은 방법이기 때문에 이를 하이퍼파라미터 변수로 설정하는게 좋습니다.\n","\n","input_size = 7\n","batch_size = 4\n","hidden_size = 3\n","seq_len = 2\n","\n","rnn = nn.LSTM(input_size, hidden_size, seq_len, batch_first=True)\n","\n","input_ = torch.randn(batch_size, hidden_size, input_size)\n","h0 = torch.randn(seq_len, batch_size, hidden_size)\n","c0 = torch.randn(seq_len, batch_size, hidden_size)\n","\n","output, (hidden_state, cell_state) = rnn(input_, (h0, c0))\n","\n","print(input_.size(),h0.size(),c0.size())\n","print(output.size(),hidden_state.size(),cell_state.size())"],"execution_count":5,"outputs":[{"output_type":"stream","text":["torch.Size([4, 3, 7]) torch.Size([2, 4, 3]) torch.Size([2, 4, 3])\n","torch.Size([4, 3, 3]) torch.Size([2, 4, 3]) torch.Size([2, 4, 3])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ulgKrnCY_IRW","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}